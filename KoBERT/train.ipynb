{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 87290 examples [00:00, 1745868.26 examples/s]\n",
      "Generating validation split: 10911 examples [00:00, 1363973.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"json\", data_files={\"train\":\"splits/train.jsonl\",\n",
    "                                    \"validation\":\"splits/dev.jsonl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a227888",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m WORK_DIR     \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./kobert-emotion\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m SEED         \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(WORK_DIR, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# -------------------- 1) JSONL 데이터 로드 ----------------------\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 아래 경로를 실제 파일명으로 바꿔주세요.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\transformers\\trainer_utils.py:105\u001b[0m, in \u001b[0;36mset_seed\u001b[1;34m(seed, deterministic)\u001b[0m\n\u001b[0;32m    103\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\_compile.py:31\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\random.py:46\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\cuda\\random.py:127\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    124\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m    125\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 127\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\cuda\\__init__.py:244\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[1;32mc:\\Users\\xpc\\anaconda3\\envs\\cs224n_dfp\\lib\\site-packages\\torch\\cuda\\random.py:125\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m    124\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m--> 125\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# -------------------------- 설정 --------------------------\n",
    "MODEL_NAME   = \"skt/kobert-base-v1\"\n",
    "MAX_LEN      = 128\n",
    "BATCH_SIZE   = 16\n",
    "LR           = 2e-5\n",
    "EPOCHS       = 5\n",
    "WORK_DIR     = \"./kobert-emotion\"\n",
    "SEED         = 42\n",
    "\n",
    "set_seed(SEED)\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- 1) JSONL 데이터 로드 ----------------------\n",
    "# 아래 경로를 실제 파일명으로 바꿔주세요.\n",
    "data_files = {\n",
    "    \"train\":      \"emotion_train_dataset.jsonl\",\n",
    "    \"validation\": \"emotion_valid_dataset.jsonl\",\n",
    "    # \"test\":    \"emotion_test_dataset.jsonl\",  # 테스트셋이 있으면 주석 해제\n",
    "}\n",
    "ds = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# -------------------- 2) \"label_id\" → \"labels\" rename ----------------------\n",
    "# Trainer는 \"labels\" 컬럼을 기대하기 때문에 이름을 바꿔줍니다.\n",
    "ds = ds.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "# -------------------- 3) 토크나이저 & 토큰화 ----------------------------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tok(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=False,            # DataCollatorWithPadding가 패딩을 처리\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "# \"text\" 컬럼을 없애고 input_ids·attention_mask만 남기기\n",
    "ds_enc = ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# 마지막으로, Trainer에게 넘길 형식(텐서) 지정\n",
    "ds_enc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# -------------------- 4) DataCollator, 모델, 지표 -------------------------\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tok, pad_to_multiple_of=8)\n",
    "\n",
    "# 레이블 수는 데이터셋에 있는 고유 label_id 개수와 일치하도록 설정하세요.\n",
    "# 예를 들어 0~6 범위라면 num_labels=7\n",
    "num_labels = len(set(ds_enc[\"train\"][\"labels\"].numpy().tolist()))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1  = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc   = metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1    = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"macro_f1\": f1}\n",
    "\n",
    "# -------------------- 5) Trainer & 학습 인자 ------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir               = WORK_DIR,\n",
    "    evaluation_strategy      = \"epoch\",\n",
    "    save_strategy            = \"epoch\",\n",
    "    load_best_model_at_end   = True,\n",
    "    metric_for_best_model    = \"macro_f1\",\n",
    "    greater_is_better        = True,\n",
    "\n",
    "    num_train_epochs         = EPOCHS,\n",
    "    per_device_train_batch_size  = BATCH_SIZE,\n",
    "    per_device_eval_batch_size   = BATCH_SIZE * 2,\n",
    "    learning_rate            = LR,\n",
    "    weight_decay             = 0.01,\n",
    "    fp16                     = torch.cuda.is_available(),\n",
    "    report_to                = \"none\",\n",
    "    seed                     = SEED,\n",
    "    save_total_limit         = 2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = ds_enc[\"train\"],\n",
    "    eval_dataset    = ds_enc[\"validation\"],\n",
    "    tokenizer       = tok,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "# -------------------- 6) 학습 및 저장 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"▶️ 학습 샘플 수: {len(ds_enc['train'])}\")\n",
    "    print(f\"▶️ 검증 샘플 수: {len(ds_enc['validation'])}\")\n",
    "    if \"test\" in ds_enc:\n",
    "        print(f\"▶️ 테스트 샘플 수: {len(ds_enc['test'])}\")\n",
    "\n",
    "    print(\"🚀 학습 시작...\")\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"💾 최종 모델 저장 중...\")\n",
    "    trainer.save_model(WORK_DIR)\n",
    "    tok.save_pretrained(WORK_DIR)\n",
    "\n",
    "    print(\"✅ 저장 완료! 모델 및 토크나이저가 다음 경로에 저장되었습니다:\")\n",
    "    print(os.path.abspath(WORK_DIR))\n",
    "\n",
    "    # -------------------- 7) (Optional) 테스트셋 평가 --------------------------\n",
    "    if \"test\" in ds_enc:\n",
    "        print(\"\\n📊 테스트셋 평가 결과:\")\n",
    "        test_metrics = trainer.evaluate(ds_enc[\"test\"])\n",
    "        for k, v in test_metrics.items():\n",
    "            print(f\"   {k}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n_dfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
