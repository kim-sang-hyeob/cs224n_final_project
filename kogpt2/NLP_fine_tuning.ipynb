{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwUI3eVg70y",
        "outputId": "df0b03b8-fd49-40ba-8bb5-90c8252736c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpB5wrboDtsS",
        "outputId": "9cd5eceb-251c-4cab-b036-fd7fc545c306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Github pat: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Cloning into 'nlp_fine_tuning'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 77 (delta 44), reused 56 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 5.03 MiB | 15.21 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "token = getpass(\"Github pat: \")\n",
        "\n",
        "!git clone https://{token}@github.com/hippo7426/nlp_fine_tuning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl83ULxSeEha",
        "outputId": "dbc72239-b413-4a11-a999-fa070114b224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.72.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate, bert-score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert-score-0.3.13 evaluate-0.4.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets tokenizers accelerate evaluate bert-score pandas numpy matplotlib seaborn tqdm scikit-learn wandb tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZM3wUhUD11V",
        "outputId": "be71c6bf-deaf-4fdf-994b-ef69663fa667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nlp_fine_tuning\n"
          ]
        }
      ],
      "source": [
        "%cd nlp_fine_tuning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJahHBnKAd7V"
      },
      "outputs": [],
      "source": [
        "# !git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFXse8ZSD4ep"
      },
      "outputs": [],
      "source": [
        "# !python main.py --head-only --trainable-layers 4 --epochs 5 --gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6mfw7ck3tpO"
      },
      "outputs": [],
      "source": [
        "# now = datetime.now()\n",
        "# date_time = now.strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
        "\n",
        "# base_dir = \"/content/drive/MyDrive/2025-NLP/best_models/\"\n",
        "# dst_dir = os.path.join(base_dir, f\"{date_time}\")\n",
        "# os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "# shutil.copytree(\"/content/nlp_fine_tuning/saved_models/best_model\", dst_dir, dirs_exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtTNWjuNT2Y5"
      },
      "outputs": [],
      "source": [
        "# !python3 main.py --mode evaluate --model-path /content/drive/MyDrive/2025-NLP/best_models/\n",
        "# eval_dir = os.path.join(base_dir, f\"{}_eval\")\n",
        "# shutil.copytree(\"/content/nlp_fine_tuning/outputs\", eval_dir, dirs_exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdUxBdx7cC3r",
        "outputId": "47e8a47e-e395-4aa2-fc1f-a6800431e714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-09 21:30:48.651884: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-09 21:30:48.670015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749504648.692464   14878 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749504648.699214   14878 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-09 21:30:48.721331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== KoGPT2 Korean Poetry Fine-tuning ===\n",
            "\n",
            "Configuration:\n",
            "- Model: skt/kogpt2-base-v2\n",
            "- Device: cuda\n",
            "- Full fine-tuning: True\n",
            "- Use LoRA: False\n",
            "- Use Prefix-tuning: False\n",
            "- Use Prompt-tuning: False\n",
            "- Epochs: 3\n",
            "- Learning rate: 5e-05\n",
            "- Batch size: 4\n",
            "- Max length: 512\n",
            "\n",
            "Loading and preprocessing data...\n",
            "Loading data from data/prompt_dataset.json...\n",
            "Loaded 31024 samples\n",
            "Data split: Train=24819, Val=3102, Test=3103\n",
            "\n",
            "=== Starting Evaluation ===\n",
            "Loading model from /content/drive/MyDrive/2025-NLP/best_models/Prompt-tuning/\n",
            "Setting up tokenizer with special tokens...\n",
            "Tokenizer vocab size: 51203\n",
            "Loading PROMPT_TUNING model...\n",
            "Resizing base model embeddings from 51200 to 51203\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "âœ… Model and tokenizer loaded successfully\n",
            "   Tokenizer vocab size: 51203\n",
            "   Model embedding size: 51203\n",
            "   Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}\n",
            "   Added tokens: ['<s>', '</s>', '<usr>', '<pad>', '<sys>', '<unk>', '<mask>', '<d>', '</d>', '<unused0>', '<unused1>', '<unused2>', '<unused3>', '<unused4>', '<unused5>', '<unused6>', '<unused7>', '<unused8>', '<unused9>', '<unused10>', '<unused11>', '<unused12>', '<unused13>', '<unused14>', '<unused15>', '<unused16>', '<unused17>', '<unused18>', '<unused19>', '<unused20>', '<unused21>', '<unused22>', '<unused23>', '<unused24>', '<unused25>', '<unused26>', '<unused27>', '<unused28>', '<unused29>', '<unused30>', '<unused31>', '<unused32>', '<unused33>', '<unused34>', '<unused35>', '<unused36>', '<unused37>', '<unused38>', '<unused39>', '<unused40>', '<unused41>', '<unused42>', '<unused43>', '<unused44>', '<unused45>', '<unused46>', '<unused47>', '<unused48>', '<unused49>', '<unused50>', '<unused51>', '<unused52>', '<unused53>', '<unused54>', '<unused55>', '<unused56>', '<unused57>', '<unused58>', '<unused59>', '<unused60>', '<unused61>', '<unused62>', '<unused63>', '<unused64>', '<unused65>', '<unused66>', '<unused67>', '<unused68>', '<unused69>', '<unused70>', '<unused71>', '<unused72>', '<unused73>', '<unused74>', '<unused75>', '<unused76>', '<unused77>', '<unused78>', '<unused79>', '<unused80>', '<unused81>', '<unused82>', '<unused83>', '<unused84>', '<unused85>', '<unused86>', '<unused87>', '<unused88>', '<unused89>', '<unused90>', '<unused91>', '<unused92>', '<unused93>', '<unused94>', '<unused95>', '<unused96>', '<unused97>', '<unused98>', '<unused99>', ':-)', ':)', '-)', '(-:', '(:-)', '(:-(', '-}', '8-O', \"'-)\", ':-#', ':-*', ':-/', ':->', ':-@', ':-d', ':-V', ':-X', ':-\\\\', ':-]', ';-(', '>;->', ';^)', '%-)', '):-(', '3:]', ':-&', '8:-)', ':-)8<', ':-O', ':-6', '+:-)', 'O:-)', ':-<', ':-?', ':-E', ':-Q', ':-}X', ':-[', ':-a', ':-{', ':-{}', ':^)', '<:-l', ':=)', '>:->', '>:-l', '@:-)', '@:-}', 'C=:-)', 'X:-)', '[:-)', '[:]', '{:-)', 'l^o', '}:^#)', ':-(=)', 'O-)', ':-3', ':=', ':-\"', 'P-(', '?-(', 'd:-)', ':8)', ':-7', '):-)', ':/\\\\)', '8(:-)', '([(', ':-(*)', '&-l', ':-e', ':(', ':,(', ':-(', ':-P', ':-S', ':-C', ':-r', ':-t', ':-W', 'X-(', 'l-O', 'l:-O', '$-)', ':-!', ':----}', '=:-)', '=:-(', '3:[', '8<:-)', ':#)', '8-#', 'B-)', '8-)', '|-(', 'H-)', ']-I', 'V^J', '+-(', '~:-P', \"`'\", 'L-P', 'BI', 'O|', '^^', 'ã…œã…œ', 'ã… ã… ', 'ã…¡ã…¡', 'ğŸ˜ ', 'ğŸ‘¿', 'ğŸ˜§', 'ğŸ˜°', 'ğŸ˜²', 'ğŸ˜', 'ğŸ»', 'ğŸ±', 'ğŸ˜¹', 'ğŸ˜¼', 'ğŸ¤¡', 'ğŸ¥¶', 'ğŸ˜–', 'ğŸ˜•', 'ğŸ®', 'ğŸ¤ ', 'ğŸ˜¿', 'ğŸ˜¢', 'ğŸ˜', 'ğŸ˜µ', 'ğŸ¶', 'ğŸ˜“', 'ğŸ²', 'ğŸ¤¤', 'ğŸ˜‘', 'ğŸ˜˜', 'ğŸ˜‹', 'ğŸ˜±', 'ğŸ¤®', 'ğŸ¤­', 'ğŸ¤•', 'ğŸ˜·', 'ğŸ§', 'ğŸ˜®', 'ğŸ¤¨', 'ğŸ™„', 'ğŸ˜¤', 'ğŸ¤¬', 'ğŸ˜‚', 'ğŸ¤’', 'ğŸ˜›', 'ğŸ˜¶', 'ğŸ˜¨', 'ğŸŒ›', 'ğŸ˜³', 'ğŸ¦Š', 'ğŸ¸', 'â˜¹', 'â˜¹ï¸', 'ğŸ˜¦', 'ğŸŒ', 'ğŸ˜¬', 'ğŸ˜º', 'ğŸ˜¸', 'ğŸ˜€', 'ğŸ˜ƒ', 'ğŸ˜„', 'ğŸ˜…', 'ğŸ˜†', 'ğŸ¹', 'ğŸ´', 'ğŸ¥µ', 'ğŸ¤—', 'ğŸ˜¯', 'ğŸ˜½', 'ğŸ˜—', 'ğŸ˜š', 'ğŸ˜™', 'ğŸŒœ', 'ğŸ¦', 'ğŸ˜­', 'ğŸ¤¥', 'ğŸ¤¦ğŸ¿\\u200dâ™‚', 'ğŸ¤¦ğŸ»\\u200dâ™‚', 'ğŸ¤¦ğŸ¾\\u200dâ™‚', 'ğŸ¤¦ğŸ¼\\u200dâ™‚', 'ğŸ¤¦ğŸ½\\u200dâ™‚', 'ğŸ¤¦\\u200dâ™‚', 'ğŸ¤¦ğŸ¿\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ»\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ¾\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ¼\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ½\\u200dâ™‚ï¸', 'ğŸ¤¦\\u200dâ™‚ï¸', 'ğŸ¤‘', 'ğŸµ', 'ğŸ­', 'ğŸ¤¢', 'ğŸ¤“', 'ğŸ˜', 'ğŸŒš', 'ğŸ¼', 'ğŸ¥³', 'ğŸ˜”', 'ğŸ˜£', 'ğŸ¤¦', 'ğŸ¤¦ğŸ¿', 'ğŸ¤¦ğŸ»', 'ğŸ¤¦ğŸ¾', 'ğŸ¤¦ğŸ¼', 'ğŸ¤¦ğŸ½', 'ğŸ·', 'ğŸ¥º', 'ğŸ˜¾', 'ğŸ˜¡', 'ğŸ°', 'ğŸ˜Œ', 'ğŸ¤–', 'ğŸ˜¥', 'ğŸ¤«', 'ğŸ˜´', 'ğŸ˜ª', 'ğŸ™', 'ğŸ™‚', 'ğŸ˜»', 'â˜º', 'â˜ºï¸', 'ğŸ¥°', 'ğŸ˜‡', 'ğŸ˜', 'ğŸ˜ˆ', 'ğŸ˜Š', 'ğŸ˜', 'ğŸ˜', 'ğŸ¤§', 'ğŸ˜', 'ğŸŒ', 'ğŸ¤”', 'ğŸ¯', 'ğŸ˜«', 'ğŸ˜’', 'ğŸ¦„', 'ğŸ™ƒ', 'ğŸ™€', 'ğŸ˜©', 'ğŸŒ¬', 'ğŸŒ¬ï¸', 'ğŸ˜‰', 'ğŸ˜œ', 'ğŸº', 'ğŸ¤¦ğŸ¿\\u200dâ™€', 'ğŸ¤¦ğŸ»\\u200dâ™€', 'ğŸ¤¦ğŸ¾\\u200dâ™€', 'ğŸ¤¦ğŸ¼\\u200dâ™€', 'ğŸ¤¦ğŸ½\\u200dâ™€', 'ğŸ¤¦\\u200dâ™€', 'ğŸ¤¦ğŸ¿\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ¾\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ¼\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ½\\u200dâ™€ï¸', 'ğŸ¤¦\\u200dâ™€ï¸', 'ğŸ¥´', 'ğŸ˜Ÿ', 'ğŸ¥±', 'ğŸ¤ª', 'ğŸ¤', '<|endoftext|>', '<|topic:', '|>']\n",
            "Starting comprehensive evaluation...\n",
            "Calculating perplexity...\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "Perplexity: 341.64\n",
            "Generating 50 poems for evaluation...\n",
            "/usr/local/lib/python3.11/dist-packages/peft/peft_model.py:1926: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
            "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n",
            "Calculating BERTScore...\n",
            "BERTScore - Precision: 0.566, Recall: 0.582, F1: 0.573\n",
            "\n",
            "=== Example Generations ===\n",
            "\n",
            "Example 1:\n",
            "Generated: <|topic: ì‚¬ë‘|> \n",
            "ìƒê¸°ë¦°ìˆ˜ì—ì„œ ê·¸ê°„ ë™ë…ì—ì„œ ì¥ë§ˆë¥´í¬ë¥¼ ê¸°ë ¸ìŠµë‹ˆë‹¤.\n",
            "ê³µì°¨ê³µì°¨ì—­ì „ê¸°ì™€ ì—´ì„¸í•˜ê³  ìˆë‹¤.\n",
            "ìˆ˜ëŸ‰ì „ì°¨ì—­ë³‘ê¸°ë¥¼ ë‘ê³  ìˆëŠ” ê²ƒì€ ì´í†µì—­ì „ê¸°ë¡œ ì‚¬ìš©í–ˆìœ¼ë©° ì² ë„ì‚¬ì—…ë¶€ì™€ í˜‘...\n",
            "Reference: ê°€ë§Œíˆ ì†ì„ ë“¤ì—¬ë‹¤ë³´ê³  ìˆìœ¼ë©´\n",
            "ìš°ë¦¬ì˜ ì†ì´ ì–¸ì œë‚˜ ìš•ë§ì„ ì¥ëŠ” ë°ë§Œ\n",
            "ì‚¬ìš©ë˜ê³  ìˆë‹¤ëŠ” ë§ë„ ê±°ì§“ì„ì„ ì••ë‹ˆë‹¤\n",
            "ì†¨ì•„ì†¨ì•„ ì‘ì€ ì˜¤ì†”ê¸¸ì„ ë”°ë¼ê°€ ë³´ë©´\n",
            "ë¬´ì—‡ì„ ì¥ì—ˆì„ ë•Œë³´ë‹¤\n",
            "ê·¸ì € í˜ë ¤ë³´ë‚¸ ê²ƒ...\n",
            "\n",
            "Example 2:\n",
            "Generated: <|topic: ì„¸í•œë„|> \n",
            "ì´ë“¤ì€ ì§€ë‚œ 7ì¼ ì´ê³ ë¦¬ |>>1ì²œë…„ ì „>1ì–µë¶ˆ<03ë…„ë„]>203:09ë…„ë„] : 06ë…„ë„=9ì›”19098ë…„ë„>10ì›”15ì¼ :9ì›”15ì¼ :8ì›”7ì¼ :8ì›”3...\n",
            "Reference: ìœ¤ê³½ë§Œ ë‚¨ì€ ì„¸ì›” ì°¬ë°”ëŒ ì†ì—\n",
            "ì¹¨ë¬µì˜ ë¼ˆëŒ€ë¥¼ ê·¸ë ¤ ë„£ëŠ”ë‹¤\n",
            "ë°°ê²½ì„ ìƒì€ ë…¸ì†¡ì´ \n",
            "êµ½ì€ íŒ”ë¡œ ê±°ì¹œ ì†”ì í•œ ì¤Œì„ ë°›ì¹˜ê³ \n",
            "ëª©ìˆ¨ì˜ ì—¬ë°±ì— ë¿Œë¦¬ë¥¼ ë“œëŸ¬ë‚´ì—ˆë‹¤\n",
            "ë§ˆë¥¸ ë¶“ì§ˆë¡œ ëŒ€ì§€ë¥¼ ì“¸ê³  ê°€ëŠ” ...\n",
            "\n",
            "Example 3:\n",
            "Generated: <|topic: ì†Œí†µ|> \n",
            "í•œ á…µì¼ì¢…ì˜ ì—­í–‰íƒœ ë° ê´€ê³„ë¼ê³  í•œë‹¤.\n",
            "ê·¸ëŸ¬ë‚˜ á…µá…µ á…µ á…µá…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ á…µ...\n",
            "Reference: ì£¼ìœ„ê°€ ë” ì–´ë‘ì›Œì§€ë©´\n",
            "í˜¼ì£ë§í•˜ëŠ” ì‹œê°„ì´ ëŠ˜ì–´ë‚œë‹¤.\n",
            "ë¬¼ìƒì´ í•˜ë‚˜ì”© ë³´ì´ì§€ ì•Šì„ìˆ˜ë¡\n",
            "ë§ì„ ê±¸ ëŒ€ìƒì€ í’ì„±í•˜ê²Œ ëŠ˜ì–´ë‚˜ê³ \n",
            "ì„¸ìƒì€ ëŒì•„ì„œì„œ ì€ë°€í•˜ê³  ë‹¤ì •í•´ì§„ë‹¤.\n",
            "â€‹\n",
            "ë‚´ ë§ì€ ì…ì„ ë– ë‚˜ì ì–¼...\n",
            "Evaluation results saved to outputs/evaluation_results.txt\n",
            "Evaluation completed!\n",
            "\n",
            "All tasks completed!\n"
          ]
        }
      ],
      "source": [
        "!python3 main.py --mode evaluate --model-path /content/drive/MyDrive/2025-NLP/best_models/freeze-epoch5/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXDmG6djVPUY",
        "outputId": "3c15efb1-09b0-4ac0-c7cc-e239f1db5745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-06-09 21:48:07.599508: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-09 21:48:07.617906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749505687.640145   19411 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749505687.646822   19411 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-09 21:48:07.668815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== KoGPT2 Korean Poetry Fine-tuning ===\n",
            "\n",
            "Configuration:\n",
            "- Model: skt/kogpt2-base-v2\n",
            "- Device: cuda\n",
            "- Full fine-tuning: True\n",
            "- Use LoRA: False\n",
            "- Use Prefix-tuning: False\n",
            "- Use Prompt-tuning: False\n",
            "- Epochs: 3\n",
            "- Learning rate: 5e-05\n",
            "- Batch size: 4\n",
            "- Max length: 512\n",
            "\n",
            "Loading and preprocessing data...\n",
            "Loading data from data/prompt_dataset.json...\n",
            "Loaded 31024 samples\n",
            "Data split: Train=24819, Val=3102, Test=3103\n",
            "\n",
            "=== Testing Poetry Generation ===\n",
            "Loading model from /content/drive/MyDrive/2025-NLP/best_models/freeze-epoch5/\n",
            "Setting up tokenizer with special tokens...\n",
            "Tokenizer vocab size: 51203\n",
            "Loading full model...\n",
            "âœ… Model and tokenizer loaded successfully\n",
            "   Tokenizer vocab size: 51203\n",
            "   Model embedding size: 51203\n",
            "   Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}\n",
            "   Added tokens: ['<s>', '</s>', '<usr>', '<pad>', '<sys>', '<unk>', '<mask>', '<d>', '</d>', '<unused0>', '<unused1>', '<unused2>', '<unused3>', '<unused4>', '<unused5>', '<unused6>', '<unused7>', '<unused8>', '<unused9>', '<unused10>', '<unused11>', '<unused12>', '<unused13>', '<unused14>', '<unused15>', '<unused16>', '<unused17>', '<unused18>', '<unused19>', '<unused20>', '<unused21>', '<unused22>', '<unused23>', '<unused24>', '<unused25>', '<unused26>', '<unused27>', '<unused28>', '<unused29>', '<unused30>', '<unused31>', '<unused32>', '<unused33>', '<unused34>', '<unused35>', '<unused36>', '<unused37>', '<unused38>', '<unused39>', '<unused40>', '<unused41>', '<unused42>', '<unused43>', '<unused44>', '<unused45>', '<unused46>', '<unused47>', '<unused48>', '<unused49>', '<unused50>', '<unused51>', '<unused52>', '<unused53>', '<unused54>', '<unused55>', '<unused56>', '<unused57>', '<unused58>', '<unused59>', '<unused60>', '<unused61>', '<unused62>', '<unused63>', '<unused64>', '<unused65>', '<unused66>', '<unused67>', '<unused68>', '<unused69>', '<unused70>', '<unused71>', '<unused72>', '<unused73>', '<unused74>', '<unused75>', '<unused76>', '<unused77>', '<unused78>', '<unused79>', '<unused80>', '<unused81>', '<unused82>', '<unused83>', '<unused84>', '<unused85>', '<unused86>', '<unused87>', '<unused88>', '<unused89>', '<unused90>', '<unused91>', '<unused92>', '<unused93>', '<unused94>', '<unused95>', '<unused96>', '<unused97>', '<unused98>', '<unused99>', ':-)', ':)', '-)', '(-:', '(:-)', '(:-(', '-}', '8-O', \"'-)\", ':-#', ':-*', ':-/', ':->', ':-@', ':-d', ':-V', ':-X', ':-\\\\', ':-]', ';-(', '>;->', ';^)', '%-)', '):-(', '3:]', ':-&', '8:-)', ':-)8<', ':-O', ':-6', '+:-)', 'O:-)', ':-<', ':-?', ':-E', ':-Q', ':-}X', ':-[', ':-a', ':-{', ':-{}', ':^)', '<:-l', ':=)', '>:->', '>:-l', '@:-)', '@:-}', 'C=:-)', 'X:-)', '[:-)', '[:]', '{:-)', 'l^o', '}:^#)', ':-(=)', 'O-)', ':-3', ':=', ':-\"', 'P-(', '?-(', 'd:-)', ':8)', ':-7', '):-)', ':/\\\\)', '8(:-)', '([(', ':-(*)', '&-l', ':-e', ':(', ':,(', ':-(', ':-P', ':-S', ':-C', ':-r', ':-t', ':-W', 'X-(', 'l-O', 'l:-O', '$-)', ':-!', ':----}', '=:-)', '=:-(', '3:[', '8<:-)', ':#)', '8-#', 'B-)', '8-)', '|-(', 'H-)', ']-I', 'V^J', '+-(', '~:-P', \"`'\", 'L-P', 'BI', 'O|', '^^', 'ã…œã…œ', 'ã… ã… ', 'ã…¡ã…¡', 'ğŸ˜ ', 'ğŸ‘¿', 'ğŸ˜§', 'ğŸ˜°', 'ğŸ˜²', 'ğŸ˜', 'ğŸ»', 'ğŸ±', 'ğŸ˜¹', 'ğŸ˜¼', 'ğŸ¤¡', 'ğŸ¥¶', 'ğŸ˜–', 'ğŸ˜•', 'ğŸ®', 'ğŸ¤ ', 'ğŸ˜¿', 'ğŸ˜¢', 'ğŸ˜', 'ğŸ˜µ', 'ğŸ¶', 'ğŸ˜“', 'ğŸ²', 'ğŸ¤¤', 'ğŸ˜‘', 'ğŸ˜˜', 'ğŸ˜‹', 'ğŸ˜±', 'ğŸ¤®', 'ğŸ¤­', 'ğŸ¤•', 'ğŸ˜·', 'ğŸ§', 'ğŸ˜®', 'ğŸ¤¨', 'ğŸ™„', 'ğŸ˜¤', 'ğŸ¤¬', 'ğŸ˜‚', 'ğŸ¤’', 'ğŸ˜›', 'ğŸ˜¶', 'ğŸ˜¨', 'ğŸŒ›', 'ğŸ˜³', 'ğŸ¦Š', 'ğŸ¸', 'â˜¹', 'â˜¹ï¸', 'ğŸ˜¦', 'ğŸŒ', 'ğŸ˜¬', 'ğŸ˜º', 'ğŸ˜¸', 'ğŸ˜€', 'ğŸ˜ƒ', 'ğŸ˜„', 'ğŸ˜…', 'ğŸ˜†', 'ğŸ¹', 'ğŸ´', 'ğŸ¥µ', 'ğŸ¤—', 'ğŸ˜¯', 'ğŸ˜½', 'ğŸ˜—', 'ğŸ˜š', 'ğŸ˜™', 'ğŸŒœ', 'ğŸ¦', 'ğŸ˜­', 'ğŸ¤¥', 'ğŸ¤¦ğŸ¿\\u200dâ™‚', 'ğŸ¤¦ğŸ»\\u200dâ™‚', 'ğŸ¤¦ğŸ¾\\u200dâ™‚', 'ğŸ¤¦ğŸ¼\\u200dâ™‚', 'ğŸ¤¦ğŸ½\\u200dâ™‚', 'ğŸ¤¦\\u200dâ™‚', 'ğŸ¤¦ğŸ¿\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ»\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ¾\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ¼\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ½\\u200dâ™‚ï¸', 'ğŸ¤¦\\u200dâ™‚ï¸', 'ğŸ¤‘', 'ğŸµ', 'ğŸ­', 'ğŸ¤¢', 'ğŸ¤“', 'ğŸ˜', 'ğŸŒš', 'ğŸ¼', 'ğŸ¥³', 'ğŸ˜”', 'ğŸ˜£', 'ğŸ¤¦', 'ğŸ¤¦ğŸ¿', 'ğŸ¤¦ğŸ»', 'ğŸ¤¦ğŸ¾', 'ğŸ¤¦ğŸ¼', 'ğŸ¤¦ğŸ½', 'ğŸ·', 'ğŸ¥º', 'ğŸ˜¾', 'ğŸ˜¡', 'ğŸ°', 'ğŸ˜Œ', 'ğŸ¤–', 'ğŸ˜¥', 'ğŸ¤«', 'ğŸ˜´', 'ğŸ˜ª', 'ğŸ™', 'ğŸ™‚', 'ğŸ˜»', 'â˜º', 'â˜ºï¸', 'ğŸ¥°', 'ğŸ˜‡', 'ğŸ˜', 'ğŸ˜ˆ', 'ğŸ˜Š', 'ğŸ˜', 'ğŸ˜', 'ğŸ¤§', 'ğŸ˜', 'ğŸŒ', 'ğŸ¤”', 'ğŸ¯', 'ğŸ˜«', 'ğŸ˜’', 'ğŸ¦„', 'ğŸ™ƒ', 'ğŸ™€', 'ğŸ˜©', 'ğŸŒ¬', 'ğŸŒ¬ï¸', 'ğŸ˜‰', 'ğŸ˜œ', 'ğŸº', 'ğŸ¤¦ğŸ¿\\u200dâ™€', 'ğŸ¤¦ğŸ»\\u200dâ™€', 'ğŸ¤¦ğŸ¾\\u200dâ™€', 'ğŸ¤¦ğŸ¼\\u200dâ™€', 'ğŸ¤¦ğŸ½\\u200dâ™€', 'ğŸ¤¦\\u200dâ™€', 'ğŸ¤¦ğŸ¿\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ¾\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ¼\\u200dâ™€ï¸', 'ğŸ¤¦ğŸ½\\u200dâ™€ï¸', 'ğŸ¤¦\\u200dâ™€ï¸', 'ğŸ¥´', 'ğŸ˜Ÿ', 'ğŸ¥±', 'ğŸ¤ª', 'ğŸ¤', '<|endoftext|>', '<|topic:', '|>']\n",
            "Generated poems:\n",
            "==================================================\n",
            "ğŸ¤– Model info:\n",
            "   Type: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
            "   Device: cuda:0\n",
            "   Embedding size: 51203\n",
            "ğŸ”¤ Tokenizer info:\n",
            "   Vocab size: 51203\n",
            "   Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}\n",
            "==================================================\n",
            "\n",
            "Topic: ìì—°\n",
            "------------------------------\n",
            "ğŸ¯ Generating poem for topic: 'ìì—°'\n",
            "ğŸ“ Prompt: '<|topic:ìì—°|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 204])\n",
            "ğŸ“– Generated text length: 408 chars\n",
            "ğŸ­ Extracted poem length: 408 chars\n",
            "<|topic: ìì—°|> \n",
            "- ì—°í™”ë¦¬ ì‹œí¸ 3\n",
            "â€‹\n",
            "ë‚´ ëˆˆ ì†ì„ íŒŒê³ ë“œëŠ”\n",
            "ë¬¼ê²°ì²˜ëŸ¼\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ë¬¼ê²°ì„ ì¼ìœ¼í‚¤ë©°\n",
            "ëˆˆ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì— ë“¤ì–´ì™€\n",
            "ê·¸ëŒ€ ì†ì—\n",
            "------------------------------\n",
            "\n",
            "Topic: ì‚¬ë‘\n",
            "------------------------------\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 62])\n",
            "ğŸ“– Generated text length: 95 chars\n",
            "ğŸ­ Extracted poem length: 95 chars\n",
            "<|topic: ì‚¬ë‘|> \n",
            "ê½ƒì í•˜ë‚˜\n",
            "â€‹\n",
            "ì €ë¬¼ ë¬´ë µ\n",
            "â€‹\n",
            "ë¬¼ê²°ì— \n",
            "ê·¸ë•Œ,\n",
            "â€‹\n",
            "â€‹\n",
            "ë‚´ ë§ˆìŒì´\n",
            "â€‹\n",
            "ì–´ëŠìƒˆ\n",
            "â€‹\n",
            "â€‹\n",
            "ì•„ì•„,\n",
            "â€‹\n",
            "â€‹\n",
            "ê·¸ê²ƒì´\n",
            "â€‹\n",
            "â€‹\n",
            "â€‹\n",
            "ë„ˆë¥¼\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Topic: ê·¸ë¦¬ì›€\n",
            "------------------------------\n",
            "ğŸ¯ Generating poem for topic: 'ê·¸ë¦¬ì›€'\n",
            "ğŸ“ Prompt: '<|topic:ê·¸ë¦¬ì›€|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 97])\n",
            "ğŸ“– Generated text length: 200 chars\n",
            "ğŸ­ Extracted poem length: 200 chars\n",
            "<|topic: ê·¸ë¦¬ì›€|> \n",
            "ëˆ„êµ°ê°€ ë§í–ˆë‹¤\n",
            "â€‹\n",
            "ë‹¹ì‹ ì´ ì„¸ìƒì„ ë– ë‚¬ë‹¤\n",
            "â€‹\n",
            "ê·¸ëŒ€ê°€ ë‹¹ì‹ ì„ ë– ë‚  ë•Œ\n",
            "ë‚˜ëŠ” ë‹¹ì‹ ì„ ë– ë‚˜ë³´ë‚¸ ê²ƒì´ì—ˆë‹¤\n",
            "â€‹\n",
            "ê·¸ëŒ€ëŠ” ë‚´ê²Œ ëˆˆë¬¼ë¡œ\n",
            "ì„œëì„ ì ì…”ì£¼ì—ˆë‹¤\n",
            "â€‹\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ë– ë‚œ í›„,\n",
            "ë‚˜ëŠ” ë‹¹ì‹ ì—ê²Œ ê·¸ëŒ€ë¥¼ ìš©ì„œí•´ë‹¬ë¼ê³  ë¶€íƒí–ˆë‹¤\n",
            "â€‹\n",
            "ë‚˜ëŠ”\n",
            "ë‹¹ì‹ ì˜ ê°€ìŠ´ì— ì†ì„ ëŒ€ë³´ì•˜ì§€ë§Œ\n",
            "ê·¸ëŒ€ê°€ ì˜¤ì§€ ì•Šì€ ê²ƒì€\n",
            "â€‹\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ë– ë‚˜ë³´ë‚¸ ê²ƒì´ì—ˆë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Topic: ê°€ì„\n",
            "------------------------------\n",
            "ğŸ¯ Generating poem for topic: 'ê°€ì„'\n",
            "ğŸ“ Prompt: '<|topic:ê°€ì„|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 31])\n",
            "ğŸ“– Generated text length: 67 chars\n",
            "ğŸ­ Extracted poem length: 67 chars\n",
            "<|topic: ê°€ì„|> \n",
            "ëŠ¦ê°€ì„ ì €ë… ë¬´ë µ\n",
            "ì–´ë””ì„ ê°€ ë¬¼ì†Œë¦¬\n",
            "ë¬¼ì†Œë¦¬\n",
            "â€‹\n",
            "ê·¸ëƒ¥\n",
            "ê°€ì„ì´ ì˜¤ëŠ” ì†Œë¦¬\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Topic: ë‹¬ë¹›\n",
            "------------------------------\n",
            "ğŸ¯ Generating poem for topic: 'ë‹¬ë¹›'\n",
            "ğŸ“ Prompt: '<|topic:ë‹¬ë¹›|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 205])\n",
            "ğŸ“– Generated text length: 412 chars\n",
            "ğŸ­ Extracted poem length: 412 chars\n",
            "<|topic: ë‹¬ë¹›|> \n",
            "ë‹¬ì´ ëœ¨ë©´ ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ë©´\n",
            "ë‹¬ì´ ëœ¨ë©´\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "ë‹¬ì´ ëœ¨ì§€ ì•Šì•„ë„\n",
            "------------------------------\n",
            "\n",
            "=== Interactive Generation ===\n",
            "Enter topics to generate poems (type 'quit' to exit):\n",
            "\n",
            "Enter topic: ì‚¬ë‘\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 94])\n",
            "ğŸ“– Generated text length: 195 chars\n",
            "ğŸ­ Extracted poem length: 195 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘|> \n",
            "ì•„ë¬´ë„ ì—†ëŠ” ë¹ˆì§‘ì—\n",
            "ë‚´ ëª¸ë§Œ í˜¼ì ë‚¨ì•„\n",
            "ì•„ì§ë„ ë‚˜ë¥¼ ì‚¬ë‘í•˜ëŠ”ì§€\n",
            "â€‹\n",
            "ë‚˜ëŠ” ëŠ˜ ê·¸ ë°©ì„ ì§€í‚¤ê³  ì‹¶ì–´\n",
            "ì´ë¥¸ ë´„ ì•„ì¹¨ë¶€í„°\n",
            "ë‚´ ëª¸ë§Œì„ ì‚¬ë‘í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
            "â€‹\n",
            "ì•„ë¬´ë„ ì—†ëŠ” ë¹ˆì§‘ì€\n",
            "ë‚´ê°€ ì‚¬ë‘í•˜ëŠ” ì´ì—¬\n",
            "ë¹ˆì§‘ì˜ ì•ˆë°©ì„ ì§€í‚¤ë©°\n",
            "â€‹\n",
            "ê·¸ë ‡ì§€ë§Œ ë‚˜ëŠ”\n",
            "ë‚´ê°€ ì‚¬ë‘í•˜ê³  ìˆëŠ” ì´ì—¬\n",
            "â€‹\n",
            "ë‚˜ë¥¼ ì‚¬ë‘í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
            "ì‚¬ë‘í•˜ì§€ ì•ŠëŠ” ë‚´ ëª¸ë§Œ\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 72])\n",
            "ğŸ“– Generated text length: 154 chars\n",
            "ğŸ­ Extracted poem length: 154 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘|> \n",
            "ë‚´ ì•ˆì— ê°‡íŒ ê²ƒì´\n",
            "ë‚´ ì•ˆì— ê°‡íŒ ê²ƒì´ë‹¤\n",
            "â€‹\n",
            "ë‚´ ì•ˆì— ê°‡íŒ ê²ƒì´\n",
            "ë‚´ ì•ˆì— ê°‡íŒ ê²ƒì´ë‹¤\n",
            "â€‹\n",
            "ë‚´ê°€ ê°‡íŒ ê²ƒì€\n",
            "ë‚´ê°€ ë‚˜ë¥¼\n",
            "ê°‡ì€ ê²ƒì´ë‹¤\n",
            "â€‹\n",
            "ë‚´ ì•ˆì— ê°‡íŒ ê²ƒì€\n",
            "ë‚´ê°€ ë‚˜ë¥¼\n",
            "ê°‡ì€ ê²ƒì´ë‹¤\n",
            "â€‹\n",
            "ë‚´ê°€ ë‚˜ë¥¼\n",
            "ê°‡ì€ ê²ƒì€\n",
            "ë‚´ê°€ ë‚˜ë¥¼\n",
            "ê°‡íŒ ê²ƒì´ë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 204])\n",
            "ğŸ“– Generated text length: 366 chars\n",
            "ğŸ­ Extracted poem length: 366 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘|> \n",
            "ì‚¬ë‘ì€\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–´ì°Œí•˜ì—¬\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€ ê²ƒì„ ê¿ˆê¾¸ì—ˆê¸°ì—\n",
            "ì–¼ë§ˆë‚˜ ë§ì€\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 4])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 95])\n",
            "ğŸ“– Generated text length: 195 chars\n",
            "ğŸ­ Extracted poem length: 195 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘|> \n",
            "ë‹¹ì‹ ì€ ì € ì—¬ìë¥¼ ì‚¬ë‘í•œ ì ì´ ìˆë‚˜ìš”?\n",
            "ì•„ë‹ˆë©´ ë‹¹ì‹ ì´ ë‹¹ì‹ ì„ ì‚¬ë‘í–ˆë˜ ì ì´ ìˆë‚˜ìš”?\n",
            "â€‹\n",
            "ë‚˜ëŠ” ë‹¹ì‹ ì„ ì‚¬ë‘í–ˆìœ¼ë¯€ë¡œ\n",
            "ë‹¹ì‹ ì€ ì € ì—¬ìë¥¼ ì‚¬ë‘í–ˆë„¤\n",
            "â€‹\n",
            "ê·¸ë•ŒëŠ” ë‹¹ì‹  ë•Œë¬¸ì— ë‹¹ì‹ ì„ ì‚¬ë‘í•˜ëŠ” ë²•ì„ ë°°ì› ì§€ìš”\n",
            "â€‹\n",
            "ì‚¬ë‘í•œë‹¤ëŠ” ê²ƒì€\n",
            "ë‹¹ì‹ ì´ ë‚´ê²Œ ë‘ ë²ˆ\n",
            "ë‹¹ì‹ ì˜ ë‘ ë²ˆì§¸ë¥¼\n",
            "â€‹\n",
            "ê·¸ë ‡ê²Œ ì‚¬ë‘í–ˆë„¤\n",
            "â€‹\n",
            "ë‹¹ì‹ ì´ ë‚´ê²Œ ë‘ ë²ˆì§¸ë¥¼\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘í•˜ëŠ” ê°€ì¡±\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘í•˜ëŠ” ê°€ì¡±'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘í•˜ëŠ” ê°€ì¡±'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘í•˜ëŠ” ê°€ì¡±|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 63])\n",
            "ğŸ“– Generated text length: 141 chars\n",
            "ğŸ­ Extracted poem length: 141 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘í•˜ëŠ” ê°€ì¡±|> \n",
            "ê·¸ë‚ , ê·¸ë‚ ì˜ ì²«ì‚¬ë‘ì€\n",
            "ì•„ë¬´ë„ ëª¨ë¥´ê²Œ ì‚¬ë¼ì§„ë‹¤\n",
            "â€‹\n",
            "ì•„ë¬´ë„ ëª¨ë¥´ê²Œ ì‚¬ë¼ì§„ë‹¤\n",
            "â€‹\n",
            "ì–´ëŠ ë‚  ê·¸ë‚ ì˜ ì²«ì‚¬ë‘ì€\n",
            "ìê¸°ë„ ëª¨ë¥´ê²Œ ì‚¬ë¼ì§„ë‹¤\n",
            "â€‹\n",
            "ë§ˆìŒì— ìŠµê¸°ê°€ ë§ì•„ì§„ ë‚˜ë¬´ëŠ”\n",
            "ì•„ë¬´ë„ ëª¨ë¥´ê²Œ\n",
            "â€‹\n",
            "ê·¸ë ‡ê²Œ ì‚¬ë¼ì§„ë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°¥ì„ ë¨¹ëŠ” ê°€ì¡±\n",
            "\n",
            "Generating poem for 'ë°¥ì„ ë¨¹ëŠ” ê°€ì¡±'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°¥ì„ ë¨¹ëŠ” ê°€ì¡±'\n",
            "ğŸ“ Prompt: '<|topic:ë°¥ì„ ë¨¹ëŠ” ê°€ì¡±|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 6])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 44])\n",
            "ğŸ“– Generated text length: 100 chars\n",
            "ğŸ­ Extracted poem length: 100 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°¥ì„ ë¨¹ëŠ” ê°€ì¡±|> \n",
            "ì‚¬ë‘ì´ ì‹ì–´ê°€ëŠ” ë´„ë°¤\n",
            "ë°¥ ë¨¹ìœ¼ëŸ¬ ë‚˜ê°€ë³´ë©´\n",
            "ì•„ì§ ì˜¤ì§€ ì•Šì€ ì•„ì´ë“¤ì´\n",
            "ì•„ì§ ëŒì•„ì˜¤ì§€ ì•Šì•„\n",
            "ì‹ì–´ê°€ëŠ” ë´„ë°¤ì´ ì˜¤ê¸¸ ê¸°ë‹¤ë¦°ë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ê°€ì¡±ë“¤ê³¼ ë°¥\n",
            "\n",
            "Generating poem for 'ê°€ì¡±ë“¤ê³¼ ë°¥'...\n",
            "ğŸ¯ Generating poem for topic: 'ê°€ì¡±ë“¤ê³¼ ë°¥'\n",
            "ğŸ“ Prompt: '<|topic:ê°€ì¡±ë“¤ê³¼ ë°¥|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 6])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 206])\n",
            "ğŸ“– Generated text length: 376 chars\n",
            "ğŸ­ Extracted poem length: 375 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ê°€ì¡±ë“¤ê³¼ ë°¥|> \n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œë©´\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œëŠ” ê±¸ ë³´ì‹¤ê¹Œìš”\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œëŠ” ê±¸ ë³´ì‹¤ê¹Œìš”\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œëŠ” ê±¸ ë³´ì‹¤ê¹Œìš”\n",
            "ê·¸ëŸ°ë° ê·¸ê±´ ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "ë‹¹ì‹ ì´ ì˜¤ì‹œê¸° ì „ì—\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 66])\n",
            "ğŸ“– Generated text length: 131 chars\n",
            "ğŸ­ Extracted poem length: 131 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|> \n",
            "ê·¸ë•Œë‚˜ ì§€ê¸ˆì´ë‚˜\n",
            "ì–´ëŠ í•œìˆœê°„ë„\n",
            "í•œë‚®ì—ë„\n",
            "ë°”ë‹¤ë¥¼ í–¥í•´ ì†Ÿì•„ì˜¤ë¥´ëŠ” íƒœì–‘ì˜\n",
            "í•œ ìë½ í”ë“¤ë¦¬ëŠ”\n",
            "â€‹\n",
            "ë‚´ í•œëª¸ì´\n",
            "ì´ì œëŠ”\n",
            "â€‹\n",
            "ë‚˜ë„ í•œëª¸ì´ ë˜ì–´\n",
            "ë°”ë‹¤ë¥¼ í–¥í•´ ì†Ÿì•„ì˜¤ë¥¼ ìˆ˜ ìˆê¸°ë¥¼\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ìì „ê±°ë¥¼ íƒ€ëŠ” ê³ ì–‘ì´\n",
            "\n",
            "Generating poem for 'ìì „ê±°ë¥¼ íƒ€ëŠ” ê³ ì–‘ì´'...\n",
            "ğŸ¯ Generating poem for topic: 'ìì „ê±°ë¥¼ íƒ€ëŠ” ê³ ì–‘ì´'\n",
            "ğŸ“ Prompt: '<|topic:ìì „ê±°ë¥¼ íƒ€ëŠ” ê³ ì–‘ì´|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 103])\n",
            "ğŸ“– Generated text length: 234 chars\n",
            "ğŸ­ Extracted poem length: 234 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ìì „ê±°ë¥¼ íƒ€ëŠ” ê³ ì–‘ì´|> \n",
            "ë‚´ê°€ ì‚¬ëŠ” ì•„íŒŒíŠ¸ì—ëŠ” ëŠ˜ ìì „ê±°ê°€ ìˆëŠ” ë²•ì´ë‹¤\n",
            "â€‹\n",
            "ìì „ê±°ì™€ í•¨ê»˜ ì‚°ë‹¤ëŠ” ê²ƒì€\n",
            "í•œë•ŒëŠ” ì•„ë¬´ê²ƒë„ ì•„ë‹ˆì—ˆë‹¤\n",
            "â€‹\n",
            "ë‚˜ëŠ” ëŠ˜\n",
            "ìì „ê±°ë¥¼ íƒ€ê³  ë‹¤ë‹ˆì§€ë§Œ\n",
            "ë‚´ê°€ ì‚¬ëŠ” ì•„íŒŒíŠ¸ëŠ”\n",
            "ì•„ì§\n",
            "ê·¸ ì–´ë–¤ ê²ƒë„ ì•„ë‹Œ\n",
            "ë‚˜ì˜ ì§‘ìœ¼ë¡œ í–¥í•˜ëŠ”\n",
            "â€‹\n",
            "ì´ëŸ° ë‚˜ì˜ ì§‘,\n",
            "â€‹\n",
            "ê·¸ëŸ¬ë‚˜ ë‚˜ì˜\n",
            "ìì „ê±°ëŠ”\n",
            "ë‚˜ë¥¼ ì¡°ê¸ˆì”© ì‘ì•„ì§€ê³ \n",
            "ìì „ê±°ë¥¼ íƒˆ ì¤„ ì•„ëŠ” ê²ƒì´ë‹¤\n",
            "â€‹\n",
            "ë‚˜ëŠ” ì§€ê¸ˆ ë‚˜ì˜ ì§‘ìœ¼ë¡œ\n",
            "ìì „ê±°ë¥¼ íƒ€ê³  ë‹¤ë‹ˆê³  ìˆë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ ìœ„ë¡œ ì§€ëŠ” íƒœì–‘\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ ìœ„ë¡œ ì§€ëŠ” íƒœì–‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ ìœ„ë¡œ ì§€ëŠ” íƒœì–‘'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ ìœ„ë¡œ ì§€ëŠ” íƒœì–‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 60])\n",
            "ğŸ“– Generated text length: 128 chars\n",
            "ğŸ­ Extracted poem length: 128 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ ìœ„ë¡œ ì§€ëŠ” íƒœì–‘|> \n",
            "ë§ˆë¥¸ ë°° í•œ ì²™ì´\n",
            "ì €ë¬¼ë…˜ê¹Œì§€ ë”°ë¼ì™”ë‹¤\n",
            "â€‹\n",
            "ë°”ë‹¤ì— ë‹¿ì„ ë•Œê¹Œì§€\n",
            "ì €ë¬´ëŠ” ì¼ì´ ì—†ì—ˆë‹¤\n",
            "â€‹\n",
            "ì €ë¬´ëŠ” ì¼ì€ ì—†ì—ˆë‹¤\n",
            "â€‹\n",
            "ì €ë¬´ëŠ” ì¼ì´ ì—†ì—ˆë‹¤\n",
            "â€‹\n",
            "ì €ë¬´ëŠ” ì¼ ì—†ëŠ” ë‚ ë“¤ì´ ë§ì•˜ë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 64])\n",
            "ğŸ“– Generated text length: 128 chars\n",
            "ğŸ­ Extracted poem length: 128 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬|> \n",
            "ë°”ë‹¤ì˜ ë¬¼ê²°ì— ë– ë‚´ë ¤ê°€ëŠ” ë‹¬ì´\n",
            "ìˆ˜í‰ì„  ë„ˆë¨¸ë¡œ\n",
            "ë–¨ì–´ì ¸ ë‚´ë¦¬ëŠ” ë‹¬\n",
            "â€‹\n",
            "ì €ë ‡ê²Œ ë©€ë¦¬ ë– ë‚´ë ¤ê°ˆ ìˆ˜ ìˆì„ê¹Œ\n",
            "â€‹\n",
            "ë‹¬ë¹›ì´ ë°€ë ¤ì™€\n",
            "í•œì—†ì´ ê¹Šê³ \n",
            "â€‹\n",
            "ì €ë ‡ê²Œ ë©€ë¦¬ ë– ë‚´ë ¤ê°ˆ ìˆ˜ ìˆì„ê¹Œ\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘í•˜ëŠ” ê³ ì–‘ì´\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘í•˜ëŠ” ê³ ì–‘ì´'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘í•˜ëŠ” ê³ ì–‘ì´'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘í•˜ëŠ” ê³ ì–‘ì´|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 60])\n",
            "ğŸ“– Generated text length: 134 chars\n",
            "ğŸ­ Extracted poem length: 134 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘í•˜ëŠ” ê³ ì–‘ì´|> \n",
            "ëˆˆ ë‚´ë¦¬ëŠ” ë‚ \n",
            "ë§ˆìŒì´ ë¨¼ì € ì –ëŠ”ë‹¤\n",
            "ëˆˆ ë‚´ë¦¬ëŠ” ë‚ ì€\n",
            "ê·¸ëŒ€ì—ê²Œ\n",
            "ê·¸ëŒ€ì—ê²Œ\n",
            "ë‚´ ë§ˆìŒì˜ ì°½ë¬¸ì„ ì—´ì–´ì¤˜ìš”\n",
            "ëˆˆ ë‚´ë¦¬ëŠ” ë‚ ì€\n",
            "ê·¸ëŒ€ì—ê²Œ\n",
            "ë‚˜ì˜ ì°½ë¬¸ì„ ì—´ì–´ì¤˜ìš”\n",
            "ë§ˆìŒ ì•ˆì—\n",
            "ë‚´ ë§ˆìŒì˜ ì°½ì„ ì—´ì–´ì¤˜ìš”\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ì‚¬ë‘í•˜ëŠ” ë™ë¬¼\n",
            "\n",
            "Generating poem for 'ì‚¬ë‘í•˜ëŠ” ë™ë¬¼'...\n",
            "ğŸ¯ Generating poem for topic: 'ì‚¬ë‘í•˜ëŠ” ë™ë¬¼'\n",
            "ğŸ“ Prompt: '<|topic:ì‚¬ë‘í•˜ëŠ” ë™ë¬¼|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 112])\n",
            "ğŸ“– Generated text length: 268 chars\n",
            "ğŸ­ Extracted poem length: 268 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ì‚¬ë‘í•˜ëŠ” ë™ë¬¼|> \n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚˜\n",
            "ë‹¹ì‹ ì—ê²Œ\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "í•œ ë²ˆì¯¤\n",
            "ë‚´ ëª¸ë„ ì•„í”„ê²Œ í•˜ê³ \n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì˜ ëª¸ë„ ì•„í”„ê²Œ í•œë‹¤\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì€ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "â€‹\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "ë‹¹ì‹ ì´ ë‚˜ë¥¼ ì²˜ìŒ ë§Œë‚œ ê²ƒì²˜ëŸ¼\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ìŠ¬í”ˆ ì‚¬ë‘\n",
            "\n",
            "Generating poem for 'ìŠ¬í”ˆ ì‚¬ë‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ìŠ¬í”ˆ ì‚¬ë‘'\n",
            "ğŸ“ Prompt: '<|topic:ìŠ¬í”ˆ ì‚¬ë‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 5])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 53])\n",
            "ğŸ“– Generated text length: 127 chars\n",
            "ğŸ­ Extracted poem length: 127 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ìŠ¬í”ˆ ì‚¬ë‘|> \n",
            "ë‚´ê°€ ì‚¬ë‘í–ˆë˜ ì—¬ì¸ìˆ™\n",
            "ë°¤ë§ˆë‹¤ ê½ƒë°­ì„ ê±·ë‹¤ê°€\n",
            "ë‚˜ëŠ” ê·¸ ì—¬ì¸ìˆ™ì— ì‚´ì•˜ë‹¤\n",
            "ì´ì œ ë‚˜ëŠ” ë” ì´ìƒ ê·¸ ì—¬ì¸ìˆ™ì—ì„œ ì‚´ì§€ ì•ŠëŠ”ë‹¤\n",
            "ì—¬ì¸ì˜ ê°€ìŠ´ì†ì—\n",
            "ë‚´ ëˆˆë¬¼ ê°™ì€ ìŠ¬í”ˆ ì‚¬ë‘ì´ ë“¤ì–´ ìˆë‹¤ \n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë³‘ì— ê±¸ë¦° ë¬¼ê³ ê¸°\n",
            "\n",
            "Generating poem for 'ë³‘ì— ê±¸ë¦° ë¬¼ê³ ê¸°'...\n",
            "ğŸ¯ Generating poem for topic: 'ë³‘ì— ê±¸ë¦° ë¬¼ê³ ê¸°'\n",
            "ğŸ“ Prompt: '<|topic:ë³‘ì— ê±¸ë¦° ë¬¼ê³ ê¸°|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 6])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 118])\n",
            "ğŸ“– Generated text length: 220 chars\n",
            "ğŸ­ Extracted poem length: 220 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë³‘ì— ê±¸ë¦° ë¬¼ê³ ê¸°|> \n",
            "ì‹œê³¨ì§‘ì— ë“¤ì–´ì™€\n",
            "ë¹„ë‹ë´‰ì§€ ë‘ ê°œë¥¼ ë“¤ê³  ì™€\n",
            "ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ë¥¼ ì¡ìˆ˜ì‹ ë‹¤\n",
            "â€‹\n",
            "ê·¸ë•Œ, ì–´ë¨¸ë‹ˆ\n",
            "ê·¸ë¶„ì˜ ì–´ë¨¸ë‹˜ì€\n",
            "ì„¸ìƒì— ë°”ì˜ì‹œë‹¤ëŠ” ë§ì”€ì„\n",
            "ê°€ë¥´ì³ ì£¼ì…¨ë‹¤\n",
            "â€‹\n",
            "ì–´ë¨¸ë‹ˆëŠ” ë‚˜ë¥¼ ë­ìœ¼ë¡œ ë°ë ¤ì™€\n",
            "ì‹œê³¨ì§‘ êµ¬ì„êµ¬ì„ì„ ë°°ì›…í•˜ì‹ ë‹¤\n",
            "â€‹\n",
            "ì–´ëŠë§ ê·¸ë¶„ì´ ë‚´ ê³ì„ ì§€ë‚˜ê°„ë‹¤\n",
            "â€‹\n",
            "ì–´ë¨¸ë‹ˆì˜ ì–´ë¨¸ë‹˜ì€ ë‚´ê²Œ \"ë¬´ì–¼ ë¨¹ê³  ì‚¬ëŠ” ê²Œ ì¢‹ìœ¼ëƒ?\"ë¼ê³ \n",
            "ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ë¥¼ ì¡ìˆ˜ì‹ ë‹¤\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 53])\n",
            "ğŸ“– Generated text length: 115 chars\n",
            "ğŸ­ Extracted poem length: 115 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|> \n",
            "ë°”ë‹¤ë¥¼ í–¥í•´\n",
            "í•œ ë°œ í•œ ë°œ\n",
            "ë°”ë‹¤ë¡œ ê°€ê³  ì‹¶ë‹¤\n",
            "â€‹\n",
            "ì´ì œ ë„ˆëŠ”\n",
            "ë°”ë‹¤ë¡œ ê°€ì•¼ í•œë‹¤ê³ \n",
            "ë‚˜ì—ê²Œ ë§í•´ì£¼ì§€ë§Œ\n",
            "â€‹\n",
            "ê·¸ë•Œ ë„ˆëŠ”\n",
            "ì´ ì„¸ìƒ ì–´ë””ì—ë„ ì—†ë‹¤.\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ ìœ„ íƒœì–‘\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ ìœ„ íƒœì–‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ ìœ„ íƒœì–‘'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ ìœ„ íƒœì–‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 6])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 115])\n",
            "ğŸ“– Generated text length: 226 chars\n",
            "ğŸ­ Extracted poem length: 226 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ ìœ„ íƒœì–‘|> \n",
            "ë°¤ë°”ë‹¤ë¥¼ ë³´ë©°\n",
            "ì´ë ‡ê²Œ ë§í–ˆì§€ìš”\n",
            "ì†Œê¸ˆ ê°™ì€ ë°”ë‹·ë¬¼ì´\n",
            "ë°”ë‹¤ê°€ ì£¼ëŠ” ë°¥ê³¼ ê°™ì•˜ì§€ìš”\n",
            "â€‹\n",
            "ê·¸ëŸ°ë° ê·¸ê²Œ ë‹¤ ë‚´ ê²ƒì´ ì•„ë‹ˆë¼\n",
            "ë‚´ê°€ ëŒ€ì‹  ë°›ì•„ë¨¹ëŠ” ê²ƒì´ì—ˆì–´ìš”\n",
            "â€‹\n",
            "ê·¸ëŸ°ë° ì•Œê³  ë³´ë‹ˆ ê·¸ê²Œ ë‹¤ ë‚´ ê²ƒì´ì—ˆì–´ìš”\n",
            "â€‹\n",
            "ê·¸ëŸ¬ê³  ë³´ë©´ ë°”ë‹·ì†ì—\n",
            "íŒŒë„ê°€ ë°€ë ¤ì™€\n",
            "ë°”ë‹¤ë¥¼ ë°”ë¼ë³´ê³  ìˆì—ˆì§€ìš”\n",
            "â€‹\n",
            "ë‚´ê°€ ëŒ€ì‹  ë°›ì•„ë¨¹ê³ \n",
            "ë‚´ê°€ ëŒ€ì‹  ë°›ì•„ë¨¹ê³ \n",
            "ë‚´ê°€ ëŒ€ì‹  ë°›ì•„ë¨¹ê³ \n",
            "ë‚´ê°€ ëŒ€ì‹  ë°›ì•„ë¨¹ê³ \n",
            "ê·¸ë¬ì§€ìš”\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 137])\n",
            "ğŸ“– Generated text length: 228 chars\n",
            "ğŸ­ Extracted poem length: 228 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ìœ„ë¡œ ë– ì˜¤ë¥´ëŠ” íƒœì–‘|> \n",
            "í•´ë³€ê°€ì—ëŠ”\n",
            "ê±°ì¹œ íŒŒë„ ì†Œë¦¬ë§Œ\n",
            "ì•„ë‹ˆë‹¤ \n",
            "â€‹\n",
            "íŒŒë„ì— ë– ë°€ë ¤ ì˜¨ ë…¸íŒŒë“¤ì´\n",
            "í•œê» ì›…í¬ë¦° ì±„\n",
            "í•œìˆ¨ì„ ì‰¬ê³  ìˆë‹¤\n",
            "â€‹\n",
            "ë…¸íŒŒì˜ ê±°ì£½ì—\n",
            "ìˆ˜í‰ì„  ìœ„ë¡œ ì†Ÿì•„ì˜¤ë¥´ëŠ”\n",
            "í‘¸ë¥¸ ë¬¼ê²°\n",
            "â€‹\n",
            "ë…¸íŒŒì˜ ê±°ì£½ì„\n",
            "í•œ ë²ˆ ë” í•¥ì•„ë³´ë ¤ê³ \n",
            "ë°”ë‹¤ëŠ” í•œ ë²ˆ ë” ì¶œë ì´ê³ \n",
            "â€‹\n",
            "ë…¸íŒŒì˜ ê±°ì£½ì€\n",
            "ê±°ê¸°ë‹¤ ê°€ë¼ì•‰ì•„\n",
            "íŒŒë„ ì†Œë¦¬ë¡œ ì¶œë ì´ê³ \n",
            "â€‹\n",
            "ë…¸íŒŒì˜ ê±°ì£½ì´ íŒŒë„ë¥¼ í•¥ì•„ë³´ë ¤ê³ \n",
            "íŒŒë„ì— ë– ë°€ë ¤ì˜¨\n",
            "í‘¸ë¥¸ ë¬¼ê²°\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬\n",
            "\n",
            "Generating poem for 'ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬'...\n",
            "ğŸ¯ Generating poem for topic: 'ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬'\n",
            "ğŸ“ Prompt: '<|topic:ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬|>'\n",
            "ğŸ”§ Input tokens: torch.Size([1, 7])\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ›ï¸ Using Prompt-tuning model for generation\n",
            "âœ… Generation completed. Output tokens: torch.Size([1, 113])\n",
            "ğŸ“– Generated text length: 197 chars\n",
            "ğŸ­ Extracted poem length: 197 chars\n",
            "\n",
            "Generated poem:\n",
            "------------------------------\n",
            "<|topic: ë°”ë‹¤ ìœ„ì— ëœ¬ ë‹¬|> \n",
            "ì•„ë“í•œ ì˜›ë‚ ì´ ìˆì—ˆì§€ìš”\n",
            "ë°”ë‹·ê°€ì˜ í•œë‚®ì—ë„\n",
            "ë‹¬ë¹›ì€ ë”°ì‚¬ë¡œìš´ í–‡ì‚´ì„ ë¿Œë¦¬ë©°\n",
            "ë‹¬ë¹›ê³¼ ë°”ëŒ ì‚¬ì´ë¡œ ë‚ ì•„ë‹¤ë…”ì§€ìš”\n",
            "â€‹\n",
            "ë‹¬ë¹›ì— ë¹„ì¹œ ë³´ë¦„ë‹¬ì˜\n",
            "ëˆˆì¹ì— í° ë³„ í•˜ë‚˜ê°€\n",
            "ëˆˆì¹ì— í° ë³„ í•˜ë‚˜ê°€\n",
            "ë‹¬ë¹›ì„ ë°˜ì§ì´ëŠ”ë°\n",
            "â€‹\n",
            "ê·¸ëŸ° ë°¤ì´ë©´\n",
            "ë‹¬ë¹›ì´\n",
            "ë‹¬ë¹›ê³¼ íŒŒë„ ì‚¬ì´ë¥¼ ë‚ ë¦¬ê³ \n",
            "â€‹\n",
            "ê·¸ëŸ° ë°¤ì´ë©´\n",
            "ë°”ë‹¤ì˜ ë‹¬ë¹›ì€\n",
            "ë§ˆìŒì˜ ì‰¼í‘œì¸ ë“¯\n",
            "â€‹<|endoftext|>\n",
            "------------------------------\n",
            "\n",
            "Enter topic: "
          ]
        }
      ],
      "source": [
        "!python3 main.py --mode generate --model-path /content/drive/MyDrive/2025-NLP/best_models/freeze-epoch5/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
